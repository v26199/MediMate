{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MediMate :- Your personalized healthcare assistant powered by AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import RetrievalQA\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Downloading all the required packages by following workflow.\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader,DirectoryLoader # To load dataset.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # split data into chunks.\n",
    "from langchain.embeddings import HuggingFaceEmbeddings          # vectorization.\n",
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone                     # store vectores.\n",
    "\n",
    "from langchain.prompts import PromptTemplate                       #To give specific instruction to llm.\n",
    "from langchain.chains import RetrievalQA                          # to retrive relavent vecotors\n",
    "\n",
    "from langchain.llms import CTransformers                         #to use model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "637\n"
     ]
    }
   ],
   "source": [
    "extracted_data = load_pdf(\"data/\")\n",
    "print(len(extracted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating chunks from loaded data.\n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of my chunk: 7020\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length of my chunk:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 384\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "query_result = embeddings.embed_query(\"Hi, How are you?\")\n",
    "print(\"Length\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Data to Vectore Database \"Pinecone\"\n",
    "\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PINECONE_API_KEY = \"7f2c336d-cfe5-4932-be89-ac751167b757\"\n",
    "PINECONE_API_ENV = \"us-east-1\"\n",
    "index_name=\"medimate\"\n",
    "\n",
    "os.environ['PINECONE_API_KEY'] = PINECONE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to Pinecone!\n"
     ]
    }
   ],
   "source": [
    "def upload_data_to_pinecone(text_chunks, pinecone_api_key, index_name):\n",
    "\n",
    "  #Creating Embeddings for Each of The Text Chunks & storing\n",
    "  docsearch=PineconeVectorStore.from_texts([t.page_content for t in text_chunks], embeddings, index_name=index_name)\n",
    "\n",
    "  print(\"Data uploaded successfully to Pinecone!\")\n",
    "\n",
    "# Upload data using your API key\n",
    "upload_data_to_pinecone(text_chunks, PINECONE_API_KEY, index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = PineconeVectorStore.from_existing_index(index_name, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-'), Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'data/Medical_book.pdf'}), Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-')]\n"
     ]
    }
   ],
   "source": [
    "query = \"what is the allergy?\"\n",
    "\n",
    "docs=docsearch.similarity_search(query, k=3)\n",
    "\n",
    "print(\"Result\", docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-'),\n",
       " Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-'),\n",
       " Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'data/Medical_book.pdf'}),\n",
       " Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'data/Medical_book.pdf'}),\n",
       " Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-', metadata={'page': 135.0, 'source': 'data/Medical_book.pdf'}),\n",
       " Document(page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)', metadata={'page': 128.0, 'source': 'data/Medical_book.pdf'}),\n",
       " Document(page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)'),\n",
       " Document(page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)', metadata={'page': 128.0, 'source': 'data/Medical_book.pdf'}),\n",
       " Document(page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)'),\n",
       " Document(page_content='When thisoccurs, an allergy develops against the offending sub-stance (an allergen.)', metadata={'page': 128.0, 'source': 'data/Medical_book.pdf'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fatching top 10 matches\n",
    "    docsearch.similarity_search(query=query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now creating a propt templete.\n",
    "\n",
    "prompt_template=\"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTransformers(client=<ctransformers.llm.LLM object at 0x3107e9610>, model='/Users/vishalpatel/Desktop/openaI/MediMate/model/llama-2-7b-chat.ggmlv3.q4_0.bin', model_type='llama', config={'max_new_tokens': 512, 'temperature': 0.8})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the model to get accurate answer most relavent.\n",
    "llm = CTransformers(model=\"/Users/vishalpatel/Desktop/openaI/MediMate/model/llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "                  model_type=\"llama\",\n",
    "                  config={'max_new_tokens':512,\n",
    "                          'temperature':0.8})\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_kwargs={'k': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Downloading langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/vishalpatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vishalpatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from requests<3,>=2->langchainhub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vishalpatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from requests<3,>=2->langchainhub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vishalpatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from requests<3,>=2->langchainhub) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vishalpatel/anaconda3/envs/mchatbot/lib/python3.8/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Downloading langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240406\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_docs_chain = create_stuff_documents_chain(\n",
    "    llm, retrieval_qa_chat_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe = retrieval_chain.invoke({\"input\":\"what is the allergy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'what is the allergy?', 'context': [Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-'), Document(page_content='the itchy, scratchy nose, eyes, and throat common inallergic rhinitis .\\nThe particular allergens to which a person is sensi-')], 'answer': '\\nAssistant: Ah, I see! Based on the context you provided, it seems that the allergy being referred to is allergic rhinitis. This is a common allergic reaction that occurs when the nasal passages become inflamed due to exposure to an allergen, such as pollen, dust, or pet dander. The symptoms you mentioned, including the itchy nose, eyes, and throat, are all common signs of allergic rhinitis.'}\n"
     ]
    }
   ],
   "source": [
    "print(qe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input', 'context', 'answer'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qe.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Ah, I see! Based on the context you provided, it seems that the allergy being referred to is allergic rhinitis. This is a common allergic reaction that occurs when the nasal passages become inflamed due to exposure to an allergen, such as pollen, dust, or pet dander. The symptoms you mentioned, including the itchy nose, eyes, and throat, are all common signs of allergic rhinitis.\n"
     ]
    }
   ],
   "source": [
    "print(qe['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
